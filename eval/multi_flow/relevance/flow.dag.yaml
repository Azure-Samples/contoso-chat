id: QnA_Relevance_llm_based_dev_test
name: QnA Relevance Evaluation
environment:
  python_requirements_txt: requirements.txt
inputs:
  question:
    type: string
  context:
    type: string
  answer:
    type: string
outputs:
  gpt_relevance:
    type: object
    reference: ${concat_scores.output.gpt_relevance}
nodes:
- name: relevance_score
  type: llm
  source:
    type: code
    path: relevance_score.jinja2
  inputs:
    question: ${inputs.question}
    context: ${inputs.context}
    answer: ${inputs.answer}
    max_tokens: 256
    deployment_name: gpt-4
    temperature: 0
    chat_history: "[]"
  connection: aoai-connection
  api: chat
- name: concat_scores
  type: python
  source:
    type: code
    path: concat_scores.py
  inputs:
    relevance_score: ${relevance_score.output}
- name: aggregate_variants_results
  type: python
  source:
    type: code
    path: aggregate_variants_results.py
  inputs:
    results: ${concat_scores.output}
  aggregation: true
