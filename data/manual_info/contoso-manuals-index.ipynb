{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-generative==1.0.0b3 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_ai_generative-1.0.0b3-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: azure-ai-resources<2.0.0,>=1.0.0b1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.0.0b8)\n",
      "Requirement already satisfied: mlflow-skinny<3 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.12.1)\n",
      "Requirement already satisfied: opencensus-ext-azure~=1.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.1.13)\n",
      "Requirement already satisfied: opencensus-ext-logging<=0.1.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.1.1)\n",
      "Collecting azureml-metrics>=0.0.33 (from azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_metrics-0.0.54-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting azureml-dataprep>4.11 (from azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_dataprep-5.1.6-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting azureml-fsspec>=1 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_fsspec-1.3.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting azureml-mlflow (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_mlflow-1.56.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting fsspec>=2023.3 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: openai>=0.27.8 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.25.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.3 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.6.0)\n",
      "Collecting mmh3 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached mmh3-4.1.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.31.0)\n",
      "Requirement already satisfied: pandas>=1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.2.2)\n",
      "Collecting nltk<4,>=3.8 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting markdown<4,>=3.4 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.11 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.12.3)\n",
      "Collecting tika<3,>=2.6 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached tika-2.6.0-py3-none-any.whl\n",
      "Collecting pypdf<4,>=3.7 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pypdf-3.17.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting unstructured<1,>=0.10 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached unstructured-0.11.8-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: GitPython<4,>=3.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.1.43)\n",
      "Collecting azure-search-documents==11.4.0b11 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_search_documents-11.4.0b11-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: promptflow[azure] in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.10.0)\n",
      "Requirement already satisfied: promptflow-tools in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.4.0)\n",
      "Collecting promptflow-vectordb (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached promptflow_vectordb-0.2.10-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-search-documents==11.4.0b11->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.30.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-search-documents==11.4.0b11->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-search-documents==11.4.0b11->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.6.1)\n",
      "Requirement already satisfied: azure-ai-ml>=1.14.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-resources<2.0.0,>=1.0.0b1->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.15.0)\n",
      "Requirement already satisfied: azure-mgmt-resource<23.0.0,>=22.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-resources<2.0.0,>=1.0.0b1->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (22.0.0)\n",
      "Collecting azureml-dataprep-native<42.0.0,>=41.0.0 (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_dataprep_native-41.0.0-cp312-cp312-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting azureml-dataprep-rslex~=2.22.2dev0 (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_dataprep_rslex-2.22.2-cp312-cp312-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting cloudpickle<3.0.0,>=1.1.0 (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: azure-identity>=1.7.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.16.0)\n",
      "Requirement already satisfied: jsonschema in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.22.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (6.0.1)\n",
      "Collecting pyarrow>=0.17.0 (from azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pyarrow-16.0.0-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting fsspec>=2023.3 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pytz in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-fsspec>=1->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2024.1)\n",
      "Requirement already satisfied: psutil<6.0.0,>=5.2.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (5.9.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.62.3 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.66.4)\n",
      "Collecting azureml-telemetry (from azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_telemetry-1.56.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting azureml-core (from azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_core-1.56.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting setuptools>=69.1.0 (from azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.26.4)\n",
      "Collecting evaluate<0.6.0,>=0.3.0 (from azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.1.4)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.6.0)\n",
      "Collecting tenacity<9.0.0,>=8.2.2 (from azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<1.0.0,>=0.10.2 (from azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting azure-keyvault>=4.2.0 (from azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_keyvault-4.2.0-py2.py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting aiohttp<5.0.0,>=3.8.3 (from azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from beautifulsoup4<5,>=4.11->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from GitPython<4,>=3.1->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.0.11)\n",
      "Requirement already satisfied: click<9,>=7.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from mlflow-skinny<3->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (8.1.7)\n",
      "Requirement already satisfied: entrypoints<1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from mlflow-skinny<3->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.4)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from mlflow-skinny<3->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (7.0.0)\n",
      "Requirement already satisfied: packaging<25 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from mlflow-skinny<3->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (24.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from mlflow-skinny<3->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.25.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from mlflow-skinny<3->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.5.0)\n",
      "Collecting joblib (from nltk<4,>=3.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from nltk<4,>=3.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2024.4.28)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.7.1)\n",
      "Requirement already satisfied: sniffio in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.11.0)\n",
      "Requirement already satisfied: opencensus<1.0.0,>=0.11.4 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from opencensus-ext-azure~=1.0->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.11.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from pandas>=1->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from pandas>=1->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from requests->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from requests->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from requests->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from requests->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2024.2.2)\n",
      "Collecting chardet (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: filetype in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.2.0)\n",
      "Collecting python-magic (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached lxml-5.2.2-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tabulate in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.9.0)\n",
      "Collecting emoji (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached emoji-2.11.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting dataclasses-json (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting python-iso639 (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Collecting rapidfuzz (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached rapidfuzz-3.9.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting unstructured-client (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached unstructured_client-0.22.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: wrapt in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.16.0)\n",
      "Collecting jsonpickle (from azureml-mlflow->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached jsonpickle-3.0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: msrest>=0.6.18 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-mlflow->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.7.1)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-mlflow->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.4.0)\n",
      "Collecting azure-storage-blob<=12.19.0,>=12.5.0 (from azureml-mlflow->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: cryptography in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azureml-mlflow->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (42.0.7)\n",
      "Requirement already satisfied: google-search-results==2.4.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-tools->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.4.1)\n",
      "Collecting azureml.rag>=0.2.28 (from azureml.rag[azure,azure_cosmos_mongo_vcore,cognitive_search,elasticsearch,faiss,pinecone]>=0.2.28->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_rag-0.2.31.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pymongo-schema (from promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pymongo_schema-0.4.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langchain<0.2,>=0.1 (from promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting requests-cache~=1.1.1 (from promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached requests_cache-1.1.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.18.6)\n",
      "Requirement already satisfied: promptflow-core==1.10.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.10.0)\n",
      "Requirement already satisfied: promptflow-devkit==1.10.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.10.0)\n",
      "Requirement already satisfied: promptflow-tracing==1.10.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.10.0)\n",
      "Collecting promptflow-azure==1.10.0 (from promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached promptflow_azure-1.10.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: azure-cosmos<5.0.0,>=4.5.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-azure==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.6.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.4.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-azure==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.8.0)\n",
      "Requirement already satisfied: docutils!=0.21.post1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.21.2)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.111.0)\n",
      "Requirement already satisfied: flask<4.0.0,>=2.2.3 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.0.3)\n",
      "Requirement already satisfied: argcomplete>=3.2.3 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.3.0)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.0.0b25)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.4.6)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.14.0)\n",
      "Requirement already satisfied: flask-cors<5.0.0,>=4.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.0.1)\n",
      "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.3.0)\n",
      "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (24.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.21.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.24.0)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.1.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (10.3.0)\n",
      "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (7.0.7)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.0.1)\n",
      "Requirement already satisfied: pywin32 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (306)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.0.30)\n",
      "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.7.3)\n",
      "Requirement already satisfied: waitress<3.0.0,>=2.1.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.1.2)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from promptflow-tracing==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.24.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<5.0.0,>=3.8.3->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from aiohttp<5.0.0,>=3.8.3->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<5.0.0,>=3.8.3->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<5.0.0,>=3.8.3->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<5.0.0,>=3.8.3->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: azure-storage-file-share<13.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-ml>=1.14.0->azure-ai-resources<2.0.0,>=1.0.0b1->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (12.15.0)\n",
      "Requirement already satisfied: azure-storage-file-datalake<13.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-ai-ml>=1.14.0->azure-ai-resources<2.0.0,>=1.0.0b1->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (12.14.0)\n",
      "Requirement already satisfied: six>=1.11.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b11->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.16.0)\n",
      "Requirement already satisfied: msal>=1.24.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-identity>=1.7.0->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.28.0)\n",
      "Requirement already satisfied: msal-extensions>=0.3.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-identity>=1.7.0->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.1.0)\n",
      "Collecting azure-keyvault-certificates~=4.4 (from azure-keyvault>=4.2.0->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_keyvault_certificates-4.8.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting azure-keyvault-secrets~=4.4 (from azure-keyvault>=4.2.0->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_keyvault_secrets-4.8.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting azure-keyvault-keys~=4.5 (from azure-keyvault>=4.2.0->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_keyvault_keys-4.9.0-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting tiktoken<1,>=0.3 (from azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached tiktoken-0.5.2-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting pymongo (from azureml.rag[azure,azure_cosmos_mongo_vcore,cognitive_search,elasticsearch,faiss,pinecone]>=0.2.28->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pymongo-4.7.2-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "INFO: pip is looking at multiple versions of azureml-rag[azure,azure-cosmos-mongo-vcore,cognitive-search,elasticsearch,faiss,pinecone] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting azureml.rag[azure,azure_cosmos_mongo_vcore,cognitive_search,elasticsearch,faiss,pinecone]>=0.2.28 (from promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azureml_rag-0.2.31-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached azureml_rag-0.2.30.2-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached azureml_rag-0.2.30.1-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached azureml_rag-0.2.30-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached azureml_rag-0.2.29.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached azureml_rag-0.2.29.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached azureml_rag-0.2.29-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is still looking at multiple versions of azureml-rag[azure,azure-cosmos-mongo-vcore,cognitive-search,elasticsearch,faiss,pinecone] to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached azureml_rag-0.2.28-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting faiss-cpu~=1.7.3 (from azureml.rag[azure,azure_cosmos_mongo_vcore,cognitive_search,elasticsearch,faiss,pinecone]>=0.2.28->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached faiss-cpu-1.7.4.tar.gz (57 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pinecone-client==2.2.4 (from azureml.rag[azure,azure_cosmos_mongo_vcore,cognitive_search,elasticsearch,faiss,pinecone]>=0.2.28->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pinecone_client-2.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting loguru>=0.5.0 (from pinecone-client==2.2.4->azureml.rag[azure,azure_cosmos_mongo_vcore,cognitive_search,elasticsearch,faiss,pinecone]>=0.2.28->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from pinecone-client==2.2.4->azureml.rag[azure,azure_cosmos_mongo_vcore,cognitive_search,elasticsearch,faiss,pinecone]>=0.2.28->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.6.1)\n",
      "Requirement already satisfied: cffi>=1.12 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from cryptography->azureml-mlflow->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.16.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.6.0,>=0.3.0->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate<0.6.0,>=0.3.0->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from evaluate<0.6.0,>=0.3.0->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached xxhash-3.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate<0.6.0,>=0.3.0->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate<0.6.0,>=0.3.0->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython<4,>=3.1->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (5.0.1)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow-skinny<3->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from jsonschema->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from jsonschema->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from jsonschema->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.18.1)\n",
      "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2,>=0.1->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain<0.2,>=0.1->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2,>=0.1->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2,>=0.1->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached langsmith-0.1.57-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from msrest>=0.6.18->azureml-mlflow->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.0.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.0->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.0->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.19.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.18.2)\n",
      "Collecting cattrs>=22.2 (from requests-cache~=1.1.1->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached cattrs-23.2.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from requests-cache~=1.1.1->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.2.1)\n",
      "Collecting url-normalize>=1.4 (from requests-cache~=1.1.1->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.2.8)\n",
      "Collecting backports.tempfile (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached backports.tempfile-1.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pathspec<1.0.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting knack<0.12.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached knack-0.11.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pkginfo (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pkginfo-1.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting humanfriendly<11.0,>=4.7 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting paramiko<4.0.0,>=2.0.8 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached paramiko-3.4.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting azure-mgmt-containerregistry<11,>=8.2.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_mgmt_containerregistry-10.3.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting azure-mgmt-storage<=22.0.0,>=16.0.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_mgmt_storage-21.1.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_mgmt_keyvault-10.3.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting azure-mgmt-authorization<5,>=0.40.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_mgmt_authorization-4.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting azure-mgmt-network<=26.0.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_mgmt_network-25.3.0-py3-none-any.whl.metadata (81 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached azure_graphrbac-0.61.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached msrestazure-0.6.4-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Collecting ndg-httpsclient<=0.5.1 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached ndg_httpsclient-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting SecretStorage<4.0.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting contextlib2<22.0.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting docker<8.0.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting adal<=1.2.7,>=1.2.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached adal-1.2.7-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pyopenssl<25.0.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pyOpenSSL-24.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jmespath<2.0.0 (from azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting applicationinsights (from azureml-telemetry->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached applicationinsights-0.11.10-py2.py3-none-any.whl.metadata (982 bytes)\n",
      "Collecting docopt (from pymongo-schema->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting ete3 (from pymongo-schema->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached ete3-3.1.3-py3-none-any.whl\n",
      "Collecting xlwt (from pymongo-schema->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached xlwt-1.3.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting xlsxwriter (from pymongo-schema->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting openpyxl (from pymongo-schema->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting future>=0.18.0 (from pymongo-schema->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting scipy (from pymongo-schema->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached scipy-1.13.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting deepdiff>=6.0 (from unstructured-client->unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached deepdiff-7.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mypy-extensions>=1.0.0 (from unstructured-client->unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is looking at multiple versions of unstructured-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unstructured-client (from unstructured<1,>=0.10->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached unstructured_client-0.21.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached unstructured_client-0.21.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: fixedint==0.1.6 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.1.6)\n",
      "Requirement already satisfied: opentelemetry-api~=1.21 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.24.0)\n",
      "Requirement already satisfied: pycparser in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography->azureml-mlflow->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.22)\n",
      "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate<0.6.0,>=0.3.0->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.0.2)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (5.9.0)\n",
      "Requirement already satisfied: orjson>=3.2.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.10.3)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.1.1)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.29.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.8.2)\n",
      "Requirement already satisfied: aniso8601>=0.82 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (9.0.1)\n",
      "Requirement already satisfied: importlib-resources in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (6.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.0->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.63.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.0->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.23.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.0->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.29.0)\n",
      "Collecting pyreadline3 (from humanfriendly<11.0,>=4.7->azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: jaraco.classes in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.4.0)\n",
      "Requirement already satisfied: pywin32-ctypes>=0.2.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.2.2)\n",
      "Requirement already satisfied: pygments in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from knack<0.12.0->azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.18.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain<0.2,>=0.1->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25 (from mlflow-skinny<3->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: portalocker<3,>=1.6 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from msal-extensions>=0.3.0->azure-identity>=1.7.0->azureml-dataprep>4.11->azureml-dataprep[parquet]>4.11; extra == \"index\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (2.8.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from ndg-httpsclient<=0.5.1->azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.6.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.45b0)\n",
      "Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached bcrypt-4.1.3-cp39-abi3-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached PyNaCl-1.5.0-cp36-abi3-win_amd64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azureml-mlflow->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.2.2)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]<3.0.0,>=2.19.1->azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jeepney>=0.6 (from SecretStorage<4.0.0->azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached jeepney-0.8.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.0.3)\n",
      "Collecting backports.weakref (from backports.tempfile->azureml-core->azureml-metrics>=0.0.33->azureml-metrics[generative-ai]>=0.0.33; extra == \"evaluate\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached backports.weakref-1.0.post1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting et-xmlfile (from openpyxl->pymongo-schema->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: typer>=0.12.3 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.12.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.0->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.0->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure~=1.0->azure-ai-generative==1.0.0b3->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (4.9)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2,>=0.1->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru>=0.5.0->pinecone-client==2.2.4->azureml.rag[azure,azure_cosmos_mongo_vcore,cognitive_search,elasticsearch,faiss,pinecone]>=0.2.28->promptflow-vectordb->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3)\n",
      "  Using cached win32_setctime-1.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: httptools>=0.5.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.6.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (12.0)\n",
      "Requirement already satisfied: more-itertools in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (10.2.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (13.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\github\\azure-samples\\contoso-chat-1\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.10.0->promptflow[azure]; extra == \"promptflow\"->azure-ai-generative[evaluate,index,promptflow]==1.0.0b3) (0.1.2)\n",
      "Using cached azure_ai_generative-1.0.0b3-py3-none-any.whl (1.6 MB)\n",
      "Using cached azure_search_documents-11.4.0b11-py3-none-any.whl (312 kB)\n",
      "Using cached azureml_dataprep-5.1.6-py3-none-any.whl (252 kB)\n",
      "Using cached azureml_fsspec-1.3.1-py3-none-any.whl (16 kB)\n",
      "Using cached azureml_metrics-0.0.54-py3-none-any.whl (382 kB)\n",
      "Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
      "Using cached unstructured-0.11.8-py3-none-any.whl (1.8 MB)\n",
      "Using cached azureml_mlflow-1.56.0-py3-none-any.whl (1.0 MB)\n",
      "Using cached mmh3-4.1.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Using cached promptflow_vectordb-0.2.10-py3-none-any.whl (116 kB)\n",
      "Using cached promptflow_azure-1.10.0-py3-none-any.whl (704 kB)\n",
      "Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "Using cached azure_keyvault-4.2.0-py2.py3-none-any.whl (4.3 kB)\n",
      "Using cached azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "Using cached azureml_dataprep_native-41.0.0-cp312-cp312-win_amd64.whl (901 kB)\n",
      "Using cached azureml_dataprep_rslex-2.22.2-cp312-cp312-win_amd64.whl (18.3 MB)\n",
      "Using cached tiktoken-0.5.2-cp312-cp312-win_amd64.whl (785 kB)\n",
      "Using cached pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
      "Using cached azureml_rag-0.2.28-py3-none-any.whl (1.7 MB)\n",
      "Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Using cached evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "Using cached langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "Using cached dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Using cached pyarrow-16.0.0-cp312-cp312-win_amd64.whl (25.8 MB)\n",
      "Using cached requests_cache-1.1.1-py3-none-any.whl (60 kB)\n",
      "Using cached setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
      "Using cached tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached azureml_core-1.56.0-py3-none-any.whl (3.3 MB)\n",
      "Using cached jsonpickle-3.0.4-py3-none-any.whl (39 kB)\n",
      "Using cached azureml_telemetry-1.56.0-py3-none-any.whl (30 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached lxml-5.2.2-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "Using cached pymongo_schema-0.4.1-py3-none-any.whl (29 kB)\n",
      "Using cached python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached rapidfuzz-3.9.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Using cached unstructured_client-0.21.0-py3-none-any.whl (24 kB)\n",
      "Using cached adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Using cached azure_keyvault_certificates-4.8.0-py3-none-any.whl (114 kB)\n",
      "Using cached azure_keyvault_keys-4.9.0-py3-none-any.whl (149 kB)\n",
      "Using cached azure_keyvault_secrets-4.8.0-py3-none-any.whl (82 kB)\n",
      "Using cached azure_mgmt_authorization-4.0.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached azure_mgmt_containerregistry-10.3.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached azure_mgmt_keyvault-10.3.0-py3-none-any.whl (933 kB)\n",
      "Using cached azure_mgmt_network-25.3.0-py3-none-any.whl (660 kB)\n",
      "Using cached azure_mgmt_storage-21.1.0-py3-none-any.whl (3.0 MB)\n",
      "Using cached cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
      "Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Using cached datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Using cached knack-0.11.0-py3-none-any.whl (60 kB)\n",
      "Using cached langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "Using cached langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Using cached langsmith-0.1.57-py3-none-any.whl (121 kB)\n",
      "Using cached msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Using cached paramiko-3.4.0-py3-none-any.whl (225 kB)\n",
      "Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Using cached pymongo-4.7.2-cp312-cp312-win_amd64.whl (485 kB)\n",
      "Using cached pyOpenSSL-24.1.0-py3-none-any.whl (56 kB)\n",
      "Using cached SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "Using cached applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "Using cached backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Using cached pkginfo-1.10.0-py3-none-any.whl (30 kB)\n",
      "Using cached scipy-1.13.0-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "Using cached XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "Using cached xlwt-1.3.0-py2.py3-none-any.whl (99 kB)\n",
      "Using cached xxhash-3.4.1-cp312-cp312-win_amd64.whl (29 kB)\n",
      "Using cached bcrypt-4.1.3-cp39-abi3-win_amd64.whl (158 kB)\n",
      "Using cached jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "Using cached PyNaCl-1.5.0-cp36-abi3-win_amd64.whl (212 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
      "Building wheels for collected packages: faiss-cpu\n",
      "  Building wheel for faiss-cpu (pyproject.toml): started\n",
      "  Building wheel for faiss-cpu (pyproject.toml): finished with status 'error'\n",
      "Failed to build faiss-cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: azureml-rag 0.2.30 does not provide the extra 'elasticsearch'\n",
      "WARNING: azureml-rag 0.2.29.2 does not provide the extra 'elasticsearch'\n",
      "WARNING: azureml-rag 0.2.29.1 does not provide the extra 'elasticsearch'\n",
      "WARNING: azureml-rag 0.2.29 does not provide the extra 'elasticsearch'\n",
      "WARNING: azureml-rag 0.2.28 does not provide the extra 'elasticsearch'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for faiss-cpu (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [8 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      running build_ext\n",
      "      building 'faiss._swigfaiss' extension\n",
      "      swigging faiss\\faiss\\python\\swigfaiss.i to faiss\\faiss\\python\\swigfaiss_wrap.cpp\n",
      "      swig.exe -python -c++ -Doverride= -I/usr/local/include -Ifaiss -doxygen -DSWIGWIN -module swigfaiss -o faiss\\faiss\\python\\swigfaiss_wrap.cpp faiss\\faiss\\python\\swigfaiss.i\n",
      "      error: command 'swig.exe' failed: None\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for faiss-cpu\n",
      "ERROR: Could not build wheels for faiss-cpu, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-generative[evaluate,index,promptflow]==1.0.0b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure.ai.generative'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresources\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AIClient\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresources\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_index_data_source\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     LocalSource,\n\u001b[0;32m      5\u001b[0m     ACSOutputConfig,\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerative\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_index\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01midentity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DefaultAzureCredential\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azure.ai.generative'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.resources.client import AIClient\n",
    "from azure.ai.resources.operations._index_data_source import (\n",
    "    LocalSource,\n",
    "    ACSOutputConfig,\n",
    ")\n",
    "from azure.ai.generative.index import build_index\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "contoso_search = os.environ[\"SEARCH_SERVICE\"]\n",
    "index_name = \"contoso-manuals-index\"\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "openai_deployment = \"text-embedding-ada-002\"\n",
    "\n",
    "path_to_data = \"./manuals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment variables for cog search SDK\n",
    "os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"] = contoso_search\n",
    "\n",
    "client = AIClient.from_config(credential = DefaultAzureCredential())\n",
    "\n",
    "# Use the same index name when registering the index in AI Studio\n",
    "index = build_index(\n",
    "    output_index_name=index_name,\n",
    "    vector_store=\"azure_cognitive_search\",\n",
    "    embeddings_model=f\"azure_open_ai://deployment/{openai_deployment}/model/{openai_deployment}\",\n",
    "    data_source_url=\"/products\",\n",
    "    index_input_config=LocalSource(input_data=path_to_data),\n",
    "    acs_config=ACSOutputConfig(\n",
    "        acs_index_name=index_name,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the index so that it shows up in the project\n",
    "cloud_index = client.indexes.create_or_update(index)\n",
    "\n",
    "print(f\"Created index '{cloud_index.name}'\")\n",
    "print(f\"Local Path: {index.path}\")\n",
    "print(f\"Cloud Path: {cloud_index.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall azure-ai-generative[evaluate,index,promptflow]==1.0.0b3 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-search-documents==11.4.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
