# The Paradigm Shift

Generative AI apps and Large Language Models (LLMs) are seeing rapid adoption by individuals and enteprises, leading to new

Generative AI applications and Large Language Models (LLMs) are accelerating the rate of innovation and adoption of AI in the enterprise. And that is creating new challenges for organizations in _developing, evaluating, deploying, and scaling_ these apps. 

---

## Rethinking Paradigms

The first shift is in mindset. We need to recalibrate our ideas about AI applications. Traditionally, that meant a _machine learning (ML) app_ that used a trained model to make predictions. Now, it's a _language model (LM) app_ that uses prompts to generate original content. These LLM apps _differ_ from traditional ML apps in a few ways:

 - **The target audience is different.** Think app developers, not data scientists.
 - **The generated assets are different.** Think interactions, not just information.
 - **The evaluation metrics are different.** Think "groundedness, fluency, fairness" & accuracy.
 - **The underlying ML models are different.** Think pre-trained "Models-as-a-Service" vs. custom.

![LLM Ops](../img/concepts/01-llmops-shift.png)

---

## Reimagining Workflows

The paradigm shift from MLOps to LLMOps now requires us to **reimagine the application lifecycle** around an end-to-end development workflow that starts at _prompt engineering_ (ideation & augmentation) and ends in _LLMOps_ (operationalization).

![LLM Stage Flows](../img/concepts/03-llm-stage-flows.png)

We can think of the application development lifecycle as follows:

 - **Ideation** - is where you **define the app** to meet a business need.
 - **Augmentation** - is where you **fine-tune the app** to improve evaluated metrics.
 - **Operationalization** - is where you **deploy the app** for real-world usage at scale.

!!!abstract "Building Contoso Chat AI"
    The abstract workflow will feel more concrete when we apply the concepts to a real use case. That will be the primary focus in the remaining sections of this workshop manual.

    - **Application**: Learn about our business case and usage scenarios.
    - **Workshop**: Build the application end-to-end on the Azure AI platform.
    - **Concepts**: Understand fundamental concepts for LLM applications.
    - **Tooling**: Explore key developers tools designed with LLMOps in mind.

---

## Redesigning Tooling

We can immediately see how the new workflow requires corresponding innovation in tooling to _streamline end-to-end development_ from the early stages of ideation, to the final stages of operationalization. The Azure AI platform has been redesigned with these challenges and needs in mind, and centered around the [Azure AI Studio](https://ai.azure.comxw).


![LLM Stage Flows](../img/concepts/04-azure-ai-platform.png)

!!!abstract "Using The Azure AI Platform"
    The abstract workflow will feel more concrete when we apply the concepts to a real use case. That will be the primary focus in the remaining sections of this workshop manual.

    - **Azure AI Studio**: 
    - **Prompt Flow**: 
    - **Visual Studio Code**: 
    - **Responsible AI**: 




