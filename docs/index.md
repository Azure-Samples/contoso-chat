# Introducing LLMOps

End-to-end application development is always challenging. Building generative AI applications with Large Language Models (LLMs) is even harder, requiring developers to **think differently** about the application lifecycle given an evolution in the target audience, the generated assets, the evaluation metrics and the deployment models.

![](./img/concepts/01-llmops-shift.png)

We're calling this **LLMOps** to acknowledge the basis in MLOps, while also highlighting the paradigm shift away from traditional thinking. As you can see, the burden on developers is much higher, requiring us to innovate with new tools and services that can streamline the end-to-end development process for AI applications from prompt engineering to LLMOps.

**That is our focus in this hands-on workshop.**  <br/>By the end of the lab, you should be able to explain what LLMOps is and why it matters. And you should be familiar with tools like Azure AI Studio and Prompt Flow that help streamlime your end-to-end AI application development process from prompt engineering to LLMOps. 

**Want a deeper dive into the core concepts or thinking behind LLMOps?** <br/>Check out this related talk from Microsoft Ignite 2023.

<iframe width="1243" height="699" src="https://www.youtube.com/embed/DdOylyrTOWg" title="End-to-End AI App Development: Prompt Engineering to LLMOps | BRK203" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

