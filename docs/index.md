# Welcome, Learner! ðŸ‘‹

Building AI Applications with Large Language Models (LLMs) requires a paradigm shift from traditional "MLOps" thinking to an "LLMOps" app lifecycle defined by three stages:

- **ideation** - where you build a basic prompt flow for _your_ use case and data.
- **augmentation** - where you evaluate & refine flow against _sample & larger_ datasets
- **operationalization** - where you deploy, monitor and use flow in real-world apps.

This is a constant process of try-evaluate-iterate that can tedious and error-prone for developers building applications for deployment at cloud scale.

![LLM Lifecycle Stage Flows](./img/concepts/03-llm-stage-flows.png)

The Azure AI Platorm provides tools and services to streamline the end-to-end development process for AI applications from prompt engineering to LLMOps. In this workshop, we'll walk through the steps of building and deploying a real-world AI solution using two key tools: **Prompt Flow** and **Azure AI Studio**. 

Let's get started!