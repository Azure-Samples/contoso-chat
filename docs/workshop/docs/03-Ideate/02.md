# 3.2: Update Prompt Metadata

??? tip "OPTIONAL: <br/> If you get stuck, you can skip this step and copy over a pre-edited file. <br/> Click to expand this section to see the hidden commands to do this."
    ``` title="Tip: Use the files icon at far right to copy the text"
    cp ../docs/workshop/src/1-build/chat-0.prompty .
    ```

To execute the Prompty asset, we need specify the languge model to use for generating the response. This metadata is defined in the _frontmatter_ of the Prompty file. In this section, we'll update the metadata with model configuration and other information.

---

## 1. Update model configuration

1. Return to the Visual Studio Code terminal pane. 
1. If you are still seeing the error message from the previous step, then you are in the _Output_ tab. Switch to the _Terminal_ tab to get a command prompt.
1. Now, use this command to copy the previous prompty to a new one. 
    ```
    cp basic.prompty chat-0.prompty
    ```

1. Open `chat-0.prompty` and replace Line 11 with this one (fixing the placeholder value `<your-deployment>`):
    ```
        azure_deployment: ${env:AZURE_OPENAI_CHAT_DEPLOYMENT}
    ```

    !!! info "Prompty will use the AZURE_OPENAI_CHAT_DEPLOYMENT from the `.env` file we created earlier to find and use the OpenAI endpoint we have already deployed. That file specifies the model to use as `gpt-35-turbo`."

## 2. Edit Basic information

Basic information about the prompt template is provided at the top of the file.

* **name**: Call this prompty `Contoso Chat Prompt`
* **description**: Use:
```
A retail assistant for Contoso Outdoors products retailer.
```
* **authors**: Replace the provided name with your own.

## 3. Edit the "sample" section

The **sample** section specifies the inputs to the prompty, and supplies default values to use if no input are provided. Edit that section as well.

* **firstName**: Choose any name other than your own (for example, `Nitya`).

* **context**: Remove this entire section. (We'll update this later)

* **question**: Replace the provided text with:
```
What can you tell me about your tents?
```

Your **sample** section should now look like this:
```
sample:
  firstName: Nitya
  question: What can you tell me about your tents?
```

## 4. Run updated Prompty file

1. Run `chat-0.prompty`. (Use the Run button or press F5.)

1. Check the OUTPUT pane. You will see a response something like this:
    - `"[info] Hey Nitya! Thank you for asking about our tents. ..."`

    !!! info "Responses from Generative AI models use randomness when creating responses, and aren't always the same." 

âœ… | Your prompty model configuration is now working!

**Ideate on your own!** If you like, try changing the `firstName` and `question` fields in the Prompty file and run it again. How do your changes affect the response?
