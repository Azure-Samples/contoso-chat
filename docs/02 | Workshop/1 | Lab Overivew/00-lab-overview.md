# Lab Overview

In this lab we'll learn to _build, run, evaluate, and deploy_ a RAG-based application ("Contoso Chat") using Azure AI Studio and Prompt Flow. This gives you hands-on experience with **End-to-End LLM Application Development (LLMOps)** on Azure.


[🏠 Table Of Contents](#table-of-contents) ⎯ [🧰 Troubleshooting](#troubleshooting)


## Learning Objectives

By the end of this lab, you should be able to:

1. Explain **LLMOps** concepts & benefits.
1. Explain **Prompt Flow** concept & benefits.
1. Explain **Azure AI Studio** features & usage.
1. Use **Prompt Flow** on Visual Studio Code
1. Design **RAG-based LLM Applications**
1. Build, run, evaluate & deploy RAG-based LLM apps **on Azure**.


## Pre-Requisites

The lab is setup with the required development environment and Azure subscription. We assume you have familiary with:

1. Machine Learning & Generative AI _concepts_
1. Python & Jupyter Notebook _programming_
1. Azure, GitHub & Visual Studio Code _tooling_

> [!Important] **Note:** You will need your own laptop and GitHub account. Make sure your laptop is charged so you can complete a 75-min lab.

## Development Environment

You'll use the following resources in this lab:
 - [Contoso Chat](https://github.com/Azure-Samples/contoso-chat) - as the target application.
 - [Github Codespaces](https://github.com/codespaces) - as the dev container
 - [Visual Studio Code](https://code.visualstudio.com/) - as the default editor
 - [Azure AI Studio (Preview)](https://ai.azure.com) - for AI projects
 - [Azure ML Studio](https://ml.azure.com) - for minor configuration
 - [Azure Portal](https://portal.azure.com) - for managing Azure resources
 - [Prompt Flow](https://github.com/microsoft/promptflow) - for streamlining end-to-end LLM app dev

===