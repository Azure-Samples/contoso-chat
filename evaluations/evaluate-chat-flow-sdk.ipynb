{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://github.com/microsoft/promptflow/blob/user/singankit/pf-evals-bug-bash/src/promptflow-evals/samples/bug-bash/instructions.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "\n",
    "# Initialize Azure OpenAI Connection\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "        azure_deployment=\"gpt-4\",\n",
    "        api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"../data/data.jsonl\"\n",
    "\n",
    "df = pd.read_json(data_path, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../contoso_chat')  # Replace '/path/to/contoso_chat' with the actual path to the 'contoso_chat' folder\n",
    "\n",
    "from chat_request import get_response\n",
    "from promptflow.evals.evaluators import RelevanceEvaluator, GroundednessEvaluator, FluencyEvaluator, CoherenceEvaluator\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique id for each run with date and time\n",
    "from datetime import datetime\n",
    "run_id = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "run_id = f\"{run_id}_chat_evaluation_sdk\"    \n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.evals.evaluate import evaluate\n",
    "\n",
    "result_eval = evaluate(\n",
    "    evaluation_name=run_id,\n",
    "    data=\"../data/data.jsonl\",\n",
    "    target=get_response,\n",
    "    evaluators={\n",
    "        #\"violence\": violence_eval,\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "    },\n",
    "    # column mapping    return {\"question\": question, \"answer\": result, \"context\": context}\n",
    "    evaluator_config={\n",
    "        \"defaultS\": {\n",
    "            \"question\": \"${data.question}\",\n",
    "            \"answer\": \"${target.answer}\",\n",
    "            \"context\": \"${target.context}\",\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = pd.DataFrame(result_eval[\"rows\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save evaluation results to a JSONL file\n",
    "eval_result.to_json('eval_result.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pf-prompty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
